# üöÄ TextSummarizer ‚Äì PEGASUS Fine-Tuning + MLOps

Projet de **Text Summarization** o√π j‚Äôai finetun√©  
üëâ `google/pegasus-cnn_dailymail`  
sur le dataset **SAMSum** (r√©sum√© de conversations).

Objectif : construire un **pipeline MLOps complet** + une **API FastAPI** pour servir le mod√®le en production.

---

## üß† Ce que j‚Äôai r√©alis√©

- ‚öôÔ∏è **Pipeline MLOps complet** : ingestion, transformation, training, √©valuation, pr√©diction  
- üß† **Fine-tuning PEGASUS** pour r√©sumer des dialogues  
- ‚ö° **API FastAPI** pour faire des pr√©dictions  
- üê≥ **Support Docker**  
- üß© Architecture propre, modulaire et scalable  

Ce projet met en avant mes comp√©tences en **NLP, finetuning, MLOps, API Design** et **architecture logicielle**.

---

## üìÇ Architecture (vue simple)

```mermaid
flowchart TD
A[Data Ingestion] --> B[Data Transformation]
B --> C[Model Training]
C --> D[Model Evaluation]
D --> E[Saved Model]
E --> F[FastAPI Prediction]
```



## ‚ñ∂Ô∏è Comment ex√©cuter le projet

### 1. Cloner
```bash
git clone https://github.com/faroukelmak/textsummarizer.git
cd textsummarizer
```

### 2. Installer les d√©pendances
```bash
pip install -r requirements.txt
```

### 3. Lancer le training
```bash
python main.py
```

### 4. Lancer l‚ÄôAPI
```bash
uvicorn app:app --reload
```

API accessible ici :
‚û°Ô∏è http://localhost:8000/docs



### Workflows 

1. Config.yaml
2. Params.yaml
3. Config entity
4. configuration manager 
5. Update the components 
    - Data Ingestion 
    - Data transformation 
    - Model training
6. Create our pipeline 
    - Training Pipeline
    - Prediction Pipeline
7. Front end 
    - Api's
    - Training Api's
    - Batch Prediction Api's
